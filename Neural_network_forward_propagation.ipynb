{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  #importing libraray\n",
    "import math\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  #sigmoid fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = loadmat('C:\\\\Users\\\\PRASHANT\\\\Desktop\\\\coding dec19\\\\file_neural\\\\ex3data1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'y': array([[10],\n",
       "        [10],\n",
       "        [10],\n",
       "        ...,\n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 9]], dtype=uint8)}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_all = loadmat('C:\\\\Users\\\\PRASHANT\\\\Desktop\\\\coding dec19\\\\file_neural\\\\ex3weights.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Tue Oct 18 14:57:02 2011',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'Theta1': array([[-2.25623899e-02, -1.05624163e-08,  2.19414684e-09, ...,\n",
       "         -1.30529929e-05, -5.04175101e-06,  2.80464449e-09],\n",
       "        [-9.83811294e-02,  7.66168682e-09, -9.75873689e-09, ...,\n",
       "         -5.60134007e-05,  2.00940969e-07,  3.54422854e-09],\n",
       "        [ 1.16156052e-01, -8.77654466e-09,  8.16037764e-09, ...,\n",
       "         -1.20951657e-04, -2.33669661e-06, -7.50668099e-09],\n",
       "        ...,\n",
       "        [-1.83220638e-01, -8.89272060e-09, -9.81968100e-09, ...,\n",
       "          2.35311186e-05, -3.25484493e-06,  9.02499060e-09],\n",
       "        [-7.02096331e-01,  3.05178374e-10,  2.56061008e-09, ...,\n",
       "         -8.61759744e-04,  9.43449909e-05,  3.83761998e-09],\n",
       "        [-3.50933229e-01,  8.85876862e-09, -6.57515140e-10, ...,\n",
       "         -1.80365926e-06, -8.14464807e-06,  8.79454531e-09]]),\n",
       " 'Theta2': array([[-0.76100352, -1.21244498, -0.10187131, -2.36850085, -1.05778129,\n",
       "         -2.20823629,  0.56383834,  1.21105294,  2.21030997,  0.44456156,\n",
       "         -1.18244872,  1.04289112, -1.60558756,  1.30419943,  1.37175046,\n",
       "          1.74825095, -0.23365648, -1.52014483,  1.15324176,  0.10368082,\n",
       "         -0.37207719, -0.61530019, -0.1256836 , -2.27193038, -0.71836208,\n",
       "         -1.29690315],\n",
       "        [-0.61785176,  0.61559207, -1.26550639,  1.85745418, -0.91853319,\n",
       "         -0.05502589, -0.38589806,  1.29520853, -1.56843297, -0.97026419,\n",
       "         -2.18334895, -2.85033578, -2.07733086,  1.63163164,  0.3490229 ,\n",
       "          1.82789117, -2.44174379, -0.8563034 , -0.2982564 , -2.07947873,\n",
       "         -1.2933238 ,  0.89982032,  0.28306578,  2.31180525, -2.46444086,\n",
       "          1.45656548],\n",
       "        [-0.68934072, -1.94538151,  2.01360618, -3.12316188, -0.2361763 ,\n",
       "          1.38680947,  0.90982429, -1.54774416, -0.79830896, -0.65599834,\n",
       "          0.7353833 , -2.58593294,  0.47210839,  0.55349499,  2.51255453,\n",
       "         -2.4167454 , -1.63898627,  1.2027302 , -1.20245851, -1.83445959,\n",
       "         -1.88013027, -0.34056098,  0.23692483, -1.06137919,  1.02759232,\n",
       "         -0.47690832],\n",
       "        [-0.67832479,  0.46299226,  0.58492321, -0.1650184 ,  1.93264192,\n",
       "         -0.22965765, -1.84731492,  0.49011768,  1.07146054, -3.31905643,\n",
       "          1.54113507,  0.37371947, -0.86484681, -2.58273522,  0.97062447,\n",
       "         -0.51021867, -0.68427897, -1.64713607,  0.21153145, -0.27422442,\n",
       "          1.72599755,  1.32418658, -2.63984479, -0.08055871, -2.03510803,\n",
       "         -1.46123776],\n",
       "        [-0.59664339, -2.04481799,  2.05698407,  1.95100909,  0.17637699,\n",
       "         -2.16141218, -0.40394736,  1.80157532, -1.56278739, -0.25253004,\n",
       "          0.23586497,  0.71656699,  1.07689092, -0.35457279, -1.67743058,\n",
       "         -0.12939255, -0.67488849,  1.14066535,  1.32431237,  3.21158484,\n",
       "         -2.15888898, -2.60164082, -3.2226466 , -1.89612906, -0.87488068,\n",
       "          2.51038628],\n",
       "        [-0.87794907,  0.4344112 , -0.93161049,  0.18390778, -0.36078216,\n",
       "          0.61958137,  0.38624948, -2.65150343,  2.29710773, -2.08818098,\n",
       "         -1.86382323,  1.06057836,  0.77562146,  2.1346861 , -1.14973702,\n",
       "         -0.52081426,  0.99743429, -1.48309353, -2.3139424 ,  0.29517333,\n",
       "         -0.38704879, -2.20607697,  0.30702191, -1.17646114, -1.63462966,\n",
       "         -0.82467661],\n",
       "        [-0.52746527,  1.21564288, -1.50095981, -2.03195359, -1.52366734,\n",
       "         -2.43732079, -2.37570311, -1.39987277, -0.88735315, -0.63278873,\n",
       "          1.50450176, -1.580763  ,  0.58599217, -0.77540416,  0.94257331,\n",
       "          2.10919653,  0.54479132,  0.43773612, -1.28024228, -0.04360994,\n",
       "          1.4774997 , -1.13276949, -0.72846904,  0.04734716,  1.6574566 ,\n",
       "          1.68540944],\n",
       "        [-0.7490154 , -0.72249056, -3.15228173,  0.36577778,  0.19811362,\n",
       "         -0.73059946,  1.65263918, -2.300357  , -1.87468162,  0.98095387,\n",
       "         -1.58825159,  1.35434142,  2.17895331, -1.99239762, -2.00371362,\n",
       "         -0.388613  , -2.33992976, -2.91719062,  0.99398645, -2.70476768,\n",
       "         -1.27139772,  1.86091461, -1.20519404, -0.38014194,  0.7087181 ,\n",
       "         -2.11014003],\n",
       "        [-0.6665468 ,  0.53601845,  1.30307573, -1.03372714, -4.03084753,\n",
       "          0.58173469, -2.65717902,  0.80379994, -1.09241928,  2.49910058,\n",
       "          0.362008  ,  0.66195337, -0.92160534, -0.83123666, -2.00200952,\n",
       "         -2.94897501,  0.64564202, -1.10114694,  0.74510309,  0.58506717,\n",
       "         -1.99545251,  0.62591105,  1.80596103, -0.22309315, -1.40442136,\n",
       "         -2.1319153 ],\n",
       "        [-0.46089119, -1.43944954, -1.21809509,  0.71093011,  0.45216919,\n",
       "         -0.35953381,  0.62284954, -0.67005297, -0.7069138 ,  0.06311351,\n",
       "         -1.23199074, -1.74645233, -2.71960897, -2.21437178, -1.69307505,\n",
       "         -0.90927394,  0.87852311,  1.18664814, -1.87041262,  0.39796295,\n",
       "          1.72113872, -1.36934055,  0.8580668 , -0.24779579,  1.28009118,\n",
       "         -1.32752042]])}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(theta_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 401)\n",
      "(10, 26)\n"
     ]
    }
   ],
   "source": [
    "theta1=theta_all['Theta1']\n",
    "theta2=theta_all['Theta2']\n",
    "# swap first and last columns of Theta2, due to legacy from MATLAB indexing, \n",
    "# since the weight file ex3weights.mat was saved based on MATLAB indexing\n",
    "theta2 = np.roll(theta2, 1, axis=0)\n",
    "print(theta1.shape)\n",
    "print(theta2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400) <class 'numpy.ndarray'>\n",
      "[[10]\n",
      " [10]\n",
      " [10]\n",
      " ...\n",
      " [ 9]\n",
      " [ 9]\n",
      " [ 9]]\n",
      "(5000, 1) <class 'numpy.ndarray'>\n",
      "[[8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [8]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n"
     ]
    }
   ],
   "source": [
    "XX=data['X']\n",
    "print(XX.shape,type(XX))\n",
    "#=annots['y']\n",
    "Y = data['y']\n",
    "print(Y)\n",
    "print(Y.shape,type(Y))\n",
    "np.place(Y, Y == 10, 0)\n",
    "print(Y[4000:5000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1)\n"
     ]
    }
   ],
   "source": [
    "m,n=XX.shape\n",
    "x0=np.ones([m,1])\n",
    "X=x0\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 401) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#here we take output all column one by one normalise it and then stack then together\n",
    "# also we stack a column of one as first column\n",
    "X=np.ones([m,1])  \n",
    "div_normaliser=[]#we store factor by which divide each element of feature before passing to hypothesis\n",
    "sub_normaliser=[] #we store factor by which substarct each element of feature before passing to hypothesis\n",
    "\n",
    "#for normalisating each feature  we first substarct with mean then divide by standard deviation of each fature\n",
    "\n",
    "for j in range(0,n):   # nth column will not be included there are n column in X 0 to n-1\n",
    "    x1=XX[:,[j]]\n",
    "    #print(x1)\n",
    "    x1=np.array(x1)\n",
    "    #print(x1)\n",
    "    #sub_normaliser.append(x1.mean()) #soring for further\n",
    "    #print(\"x1 mean is \",x1.mean())\n",
    "\n",
    "   # x1=(x1-x1.mean())# substract each element with mean of that feature\n",
    "    \n",
    "    #div_normaliser.append(x1.std())#storing for further calculation\n",
    "    #print(\"x1 standard deviation is \",x1.std())\n",
    "    #x1=x1/x1.std()\n",
    "     \n",
    "    \n",
    "    #print(x1.shape,type(x1))\n",
    "    X=np.hstack([X,x1])   #one by one add all column\n",
    "\n",
    "print(X.shape,type(X))\n",
    "\n",
    "#we get n+1 column in input as column of ones is added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1) <class 'numpy.ndarray'>\n",
      "(5000, 401) <class 'numpy.ndarray'>\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(Y.shape,type(Y))\n",
    "print(X.shape,type(X))\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 401)\n",
      "(10, 26)\n",
      "(5000, 401)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "n_label=10\n",
    "\n",
    "\n",
    "print(theta1.shape)\n",
    "print(theta2.shape)\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 25)\n"
     ]
    }
   ],
   "source": [
    "A1=sigmoid(X.dot(theta1.T))\n",
    "print(A1.shape)\n",
    "a1=np.ones([A1.shape[0],1])\n",
    "A1=np.hstack([a1,A1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 26)\n",
      "(5000, 10)\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#print(\"A1 is \",A1)\n",
    "print(A1.shape)\n",
    "A2=sigmoid(A1.dot(theta2.T))\n",
    "print(A2.shape)\n",
    "output=np.argmax(A2, axis=1)\n",
    "print(Y)\n",
    "output=output.reshape((Y.shape))\n",
    "print(output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.52%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy:\", str(100 * np.mean(output == Y)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1)\n",
      "(5000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
